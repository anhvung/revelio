{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "# < 1h\n",
    "# Make basic version with no nlp\n",
    "\n",
    "# Clean code, rearrange in clear steps : panda join, slipt, preprocessing, training\n",
    "# clean Variable names (make sure it still works), add comments\n",
    "\n",
    "\n",
    "# ~1h\n",
    "# make the diy nlp with most occuring degree terms\n",
    "# test if imporvements\n",
    "\n",
    "\n",
    "\n",
    "# pandas output\n",
    "#email to ask \n",
    "\n",
    "# test rnn\n",
    "\n",
    "# improvements: cross check with friend list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6b4ccb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7785a570",
   "metadata": {},
   "source": [
    "# 0. Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f90003",
   "metadata": {},
   "source": [
    "Downloading the data, so that we don't have to do it again if we restart the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66a5f021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data downloaded\n"
     ]
    }
   ],
   "source": [
    "urls=[\"https://info0.s3.us-east-2.amazonaws.com/recruitment/positions.csv\",\"https://info0.s3.us-east-2.amazonaws.com/recruitment/education.csv\",\"https://info0.s3.us-east-2.amazonaws.com/recruitment/jobtitle_seniority.csv\"]\n",
    "\n",
    "# data folder, create if it does not exists\n",
    "os.makedirs('./data/', exist_ok=True) \n",
    "    \n",
    "# if .csv file does not exists, download it\n",
    "for url in urls:\n",
    "    path='./data/' + os.path.basename(url)\n",
    "    if not os.path.exists(path):\n",
    "        urllib.request.urlretrieve(url, path)\n",
    "        \n",
    "print('data downloaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504c1a1d",
   "metadata": {},
   "source": [
    "Loading the data into pandas data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4d89c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO dl?\n",
    "#TODO S3 bucket code?\n",
    "df_positions = pd.read_csv(\"./data/positions.csv\")\n",
    "df_education = pd.read_csv(\"./data/education.csv\")\n",
    "df_seniority = pd.read_csv(\"./data/jobtitle_seniority.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0837c4",
   "metadata": {},
   "source": [
    "# 1. Checking the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Individual data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b36a0326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>jobtitle</th>\n",
       "      <th>startdate</th>\n",
       "      <th>enddate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162425</th>\n",
       "      <td>zzdHAVxl9iQrwom22S/FLg5+2cvffV/mNepQVJd0smgtpB...</td>\n",
       "      <td>student_senior_service_college</td>\n",
       "      <td>2012-08-01</td>\n",
       "      <td>2013-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15089</th>\n",
       "      <td>zzdHAVxl9iQrwom22S/FLg5+2cvffV/mNepQVJd0smgtpB...</td>\n",
       "      <td>command_general_staff_college</td>\n",
       "      <td>2004-07-01</td>\n",
       "      <td>2005-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146169</th>\n",
       "      <td>zzdHAVxl9iQrwom22S/FLg5+2cvffV/mNepQVJd0smgtpB...</td>\n",
       "      <td>engineer_company_brigade_staff_trainer</td>\n",
       "      <td>2002-04-01</td>\n",
       "      <td>2004-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15923</th>\n",
       "      <td>zzdHAVxl9iQrwom22S/FLg5+2cvffV/mNepQVJd0smgtpB...</td>\n",
       "      <td>student_engineer_officer</td>\n",
       "      <td>1998-01-01</td>\n",
       "      <td>1998-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20486</th>\n",
       "      <td>zzdHAVxl9iQrwom22S/FLg5+2cvffV/mNepQVJd0smgtpB...</td>\n",
       "      <td>company_commander_battalion_battalion_assistant</td>\n",
       "      <td>1998-11-01</td>\n",
       "      <td>2002-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309939</th>\n",
       "      <td>zzrNxfUzwZXNkSs15haLyA4ZM3TcQvn1bQ/jHgHWG0kf/b...</td>\n",
       "      <td>partner_head_private_client_department_|_law_p...</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338504</th>\n",
       "      <td>zzvZxBSf81furoFl3PcSuHAG1BvSkUYANepQVJd0smgtpB...</td>\n",
       "      <td>coordinador_de_personal_embarcado</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334912</th>\n",
       "      <td>zzvZxBSf81furoFl3PcSuHAG1BvSkUYANepQVJd0smgtpB...</td>\n",
       "      <td>operador_|_logistics_supply_chain</td>\n",
       "      <td>2014-11-01</td>\n",
       "      <td>2015-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359048</th>\n",
       "      <td>zzvZxBSf81furoFl3PcSuHAG1BvSkUYANepQVJd0smgtpB...</td>\n",
       "      <td>supervisor_de_personal_|_maritime</td>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>2017-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248375</th>\n",
       "      <td>zzvZxBSf81furoFl3PcSuHAG1BvSkUYANepQVJd0smgtpB...</td>\n",
       "      <td>supervisor_de_personal_|_logistics_supply_chain</td>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>2016-05-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  user_id  \\\n",
       "162425  zzdHAVxl9iQrwom22S/FLg5+2cvffV/mNepQVJd0smgtpB...   \n",
       "15089   zzdHAVxl9iQrwom22S/FLg5+2cvffV/mNepQVJd0smgtpB...   \n",
       "146169  zzdHAVxl9iQrwom22S/FLg5+2cvffV/mNepQVJd0smgtpB...   \n",
       "15923   zzdHAVxl9iQrwom22S/FLg5+2cvffV/mNepQVJd0smgtpB...   \n",
       "20486   zzdHAVxl9iQrwom22S/FLg5+2cvffV/mNepQVJd0smgtpB...   \n",
       "309939  zzrNxfUzwZXNkSs15haLyA4ZM3TcQvn1bQ/jHgHWG0kf/b...   \n",
       "338504  zzvZxBSf81furoFl3PcSuHAG1BvSkUYANepQVJd0smgtpB...   \n",
       "334912  zzvZxBSf81furoFl3PcSuHAG1BvSkUYANepQVJd0smgtpB...   \n",
       "359048  zzvZxBSf81furoFl3PcSuHAG1BvSkUYANepQVJd0smgtpB...   \n",
       "248375  zzvZxBSf81furoFl3PcSuHAG1BvSkUYANepQVJd0smgtpB...   \n",
       "\n",
       "                                                 jobtitle   startdate  \\\n",
       "162425                     student_senior_service_college  2012-08-01   \n",
       "15089                       command_general_staff_college  2004-07-01   \n",
       "146169             engineer_company_brigade_staff_trainer  2002-04-01   \n",
       "15923                            student_engineer_officer  1998-01-01   \n",
       "20486     company_commander_battalion_battalion_assistant  1998-11-01   \n",
       "309939  partner_head_private_client_department_|_law_p...  1992-01-01   \n",
       "338504                  coordinador_de_personal_embarcado  2017-12-01   \n",
       "334912                  operador_|_logistics_supply_chain  2014-11-01   \n",
       "359048                  supervisor_de_personal_|_maritime  2016-05-01   \n",
       "248375    supervisor_de_personal_|_logistics_supply_chain  2015-11-01   \n",
       "\n",
       "           enddate  \n",
       "162425  2013-06-01  \n",
       "15089   2005-06-01  \n",
       "146169  2004-06-01  \n",
       "15923   1998-10-01  \n",
       "20486   2002-03-01  \n",
       "309939         NaN  \n",
       "338504         NaN  \n",
       "334912  2015-09-01  \n",
       "359048  2017-09-01  \n",
       "248375  2016-05-01  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_positions=df_positions.sort_values(by=['user_id'])\n",
    "df_positions.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bca9cec",
   "metadata": {},
   "source": [
    "#### Looking at the dates, linkedIn only has the year and month information, so date formatting is YYYY-MM-DD\n",
    "#### Position titles and fields are seperated by '\\_|\\_', words are seperated by '_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e299739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>major</th>\n",
       "      <th>startdate</th>\n",
       "      <th>enddate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99508</th>\n",
       "      <td>++5SW5MI5/h8X1hMA3QnmQ4ZM3TcQvn1bQ/jHgHWG0kf/b...</td>\n",
       "      <td>BS</td>\n",
       "      <td>1949-01-01</td>\n",
       "      <td>1953-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92083</th>\n",
       "      <td>++5qk2+uEmkI/3Z4FrBwDw4ZM3TcQvn1bQ/jHgHWG0kf/b...</td>\n",
       "      <td>BS in Electronics</td>\n",
       "      <td>1973-01-01</td>\n",
       "      <td>1978-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92505</th>\n",
       "      <td>++5qk2+uEmkI/3Z4FrBwDw4ZM3TcQvn1bQ/jHgHWG0kf/b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1984-01-01</td>\n",
       "      <td>1987-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133238</th>\n",
       "      <td>++6+hv3i5RAVsrWO8q5JEQ5+2cvffV/mNepQVJd0smgtpB...</td>\n",
       "      <td>Master Grande Ecole</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5126</th>\n",
       "      <td>++6zEVtPCi83vpPTHSY2Vg5+2cvffV/mNepQVJd0smgtpB...</td>\n",
       "      <td>Bachelor of Science (B.Sc.) (ED)</td>\n",
       "      <td>2001-01-01</td>\n",
       "      <td>2006-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  user_id  \\\n",
       "99508   ++5SW5MI5/h8X1hMA3QnmQ4ZM3TcQvn1bQ/jHgHWG0kf/b...   \n",
       "92083   ++5qk2+uEmkI/3Z4FrBwDw4ZM3TcQvn1bQ/jHgHWG0kf/b...   \n",
       "92505   ++5qk2+uEmkI/3Z4FrBwDw4ZM3TcQvn1bQ/jHgHWG0kf/b...   \n",
       "133238  ++6+hv3i5RAVsrWO8q5JEQ5+2cvffV/mNepQVJd0smgtpB...   \n",
       "5126    ++6zEVtPCi83vpPTHSY2Vg5+2cvffV/mNepQVJd0smgtpB...   \n",
       "\n",
       "                                   major   startdate     enddate  \n",
       "99508                                 BS  1949-01-01  1953-01-01  \n",
       "92083                  BS in Electronics  1973-01-01  1978-01-01  \n",
       "92505                                NaN  1984-01-01  1987-01-01  \n",
       "133238               Master Grande Ecole  2013-01-01  2016-01-01  \n",
       "5126    Bachelor of Science (B.Sc.) (ED)  2001-01-01  2006-01-01  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_education=df_education.sort_values(by=['user_id'])\n",
    "df_education.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49c69fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>jobtitle</th>\n",
       "      <th>seniority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90141</th>\n",
       "      <td>++5SW5MI5/h8X1hMA3QnmQ4ZM3TcQvn1bQ/jHgHWG0kf/b...</td>\n",
       "      <td>former_owner_presently_consultant</td>\n",
       "      <td>7.064817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71129</th>\n",
       "      <td>++5qk2+uEmkI/3Z4FrBwDw4ZM3TcQvn1bQ/jHgHWG0kf/b...</td>\n",
       "      <td>design_engineer_|_mechanical_industrial_engine...</td>\n",
       "      <td>3.331507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222292</th>\n",
       "      <td>++5qk2+uEmkI/3Z4FrBwDw4ZM3TcQvn1bQ/jHgHWG0kf/b...</td>\n",
       "      <td>owner_|_computer_network_security</td>\n",
       "      <td>7.334247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399946</th>\n",
       "      <td>++6+hv3i5RAVsrWO8q5JEQ5+2cvffV/mNepQVJd0smgtpB...</td>\n",
       "      <td>digital_communication_social_medias_activation...</td>\n",
       "      <td>4.307247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220871</th>\n",
       "      <td>++6+hv3i5RAVsrWO8q5JEQ5+2cvffV/mNepQVJd0smgtpB...</td>\n",
       "      <td>event_promoter_public_relations</td>\n",
       "      <td>1.908356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  user_id  \\\n",
       "90141   ++5SW5MI5/h8X1hMA3QnmQ4ZM3TcQvn1bQ/jHgHWG0kf/b...   \n",
       "71129   ++5qk2+uEmkI/3Z4FrBwDw4ZM3TcQvn1bQ/jHgHWG0kf/b...   \n",
       "222292  ++5qk2+uEmkI/3Z4FrBwDw4ZM3TcQvn1bQ/jHgHWG0kf/b...   \n",
       "399946  ++6+hv3i5RAVsrWO8q5JEQ5+2cvffV/mNepQVJd0smgtpB...   \n",
       "220871  ++6+hv3i5RAVsrWO8q5JEQ5+2cvffV/mNepQVJd0smgtpB...   \n",
       "\n",
       "                                                 jobtitle  seniority  \n",
       "90141                   former_owner_presently_consultant   7.064817  \n",
       "71129   design_engineer_|_mechanical_industrial_engine...   3.331507  \n",
       "222292                  owner_|_computer_network_security   7.334247  \n",
       "399946  digital_communication_social_medias_activation...   4.307247  \n",
       "220871                    event_promoter_public_relations   1.908356  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_seniority=df_seniority.sort_values(by=['user_id'])\n",
    "df_seniority.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17e8fc8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 226184 entries, 99508 to 169422\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   user_id    226184 non-null  object\n",
      " 1   major      162346 non-null  object\n",
      " 2   startdate  197556 non-null  object\n",
      " 3   enddate    190658 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 8.6+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 377585 entries, 41525 to 248375\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   user_id    377585 non-null  object\n",
      " 1   jobtitle   376136 non-null  object\n",
      " 2   startdate  368526 non-null  object\n",
      " 3   enddate    270354 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 14.4+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 416295 entries, 90141 to 126315\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   user_id    416295 non-null  object \n",
      " 1   jobtitle   414290 non-null  object \n",
      " 2   seniority  416295 non-null  float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 12.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_education.info())\n",
    "print(df_positions.info())\n",
    "print(df_seniority.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# give the number of DISTINCT users\n",
    "def count_users(df):\n",
    "    return len(pd.unique(df['user_id']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6637ed",
   "metadata": {},
   "source": [
    "#### As expected a person can have multiple education, and position entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "781fde87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   major   startdate     enddate\n",
      "92083  BS in Electronics  1973-01-01  1978-01-01\n",
      "92505                NaN  1984-01-01  1987-01-01\n",
      "                                                 jobtitle   startdate  \\\n",
      "9781                    owner_|_computer_network_security  1993-06-01   \n",
      "106525  design_engineer_|_mechanical_industrial_engine...  1984-10-01   \n",
      "\n",
      "           enddate  \n",
      "9781           NaN  \n",
      "106525  1989-05-01  \n",
      "                                                 jobtitle  seniority\n",
      "71129   design_engineer_|_mechanical_industrial_engine...   3.331507\n",
      "222292                  owner_|_computer_network_security   7.334247\n"
     ]
    }
   ],
   "source": [
    "test_id =df_education.iat[2,0]\n",
    "def get_user_history(user_id):\n",
    "    print(df_education[df_education['user_id'].str.contains(user_id,regex=False,na=False)][['major', 'startdate','enddate']])\n",
    "    print(df_positions[df_positions['user_id'].str.contains(user_id,regex=False,na=False)][['jobtitle', 'startdate','enddate']])\n",
    "    print(df_seniority[df_seniority['user_id'].str.contains(user_id,regex=False,na=False)][['jobtitle', 'seniority']])\n",
    "get_user_history(test_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing values for each df\n",
    "There are more missing values for end dates because it can the current position / education program of someone\n",
    "\n",
    "Missing values for dates are more important than for education/jobtittles to predict the age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bf4b1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id           0\n",
      "jobtitle       1449\n",
      "startdate      9059\n",
      "enddate      107231\n",
      "dtype: int64\n",
      "------\n",
      "user_id          0\n",
      "major        63838\n",
      "startdate    28628\n",
      "enddate      35526\n",
      "dtype: int64\n",
      "------\n",
      "user_id         0\n",
      "jobtitle     2005\n",
      "seniority       0\n",
      "dtype: int64\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "#Missing values\n",
    "print(df_positions.isna().sum(),'------',sep='\\n')\n",
    "print(df_education.isna().sum(),'------',sep='\\n')\n",
    "print(df_seniority.isna().sum(),'------',sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing starting dates AND enddates are problematic because it makes it hard to impute data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6518 unique users missing job date info in df_positions\n",
      "0 unique users missing seniority info\n",
      "18036 unique users missing education date info\n"
     ]
    }
   ],
   "source": [
    "df_missing_pos=df_positions[df_positions['enddate'].isna() & df_positions['startdate'].isna()]\n",
    "df_missing_sen=df_seniority[df_seniority['seniority'].isna() ]\n",
    "df_missing_edu=df_education[df_education['enddate'].isna() & df_education['startdate'].isna()]\n",
    "print(count_users(df_missing_pos),'unique users missing job date info in df_positions')\n",
    "print(count_users(df_missing_sen),'unique users missing seniority info')\n",
    "print(count_users(df_missing_edu),'unique users missing education date info')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is even more true if there are no dates for both the education and job entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "981 unique users missing dates on all education and job info\n"
     ]
    }
   ],
   "source": [
    "df_missing_all=df_missing_pos.merge(df_missing_edu, how='inner',left_on=['user_id'], right_on=['user_id'])\n",
    "print(count_users(df_missing_all),'unique users missing dates on all education and job info')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Splitting the data to get training data \n",
    "\n",
    "## dataprocessing will be done after to prevent data leakage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Choosing the training Data\n",
    "\n",
    "People with highscool information have ages that are easy to predict since most people end highschool at the same age.\n",
    "The same is true for Bachelors. \n",
    "As a general rule, the ealier the education is in terms of degree, the better it is to predict the age because of the smaller variability.\n",
    "\n",
    "Because there are more people with bachelor information (1/3 of the data) we will use the starting date of the bachelor to determine someone's age for the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3368 unique users with a highschool info\n"
     ]
    }
   ],
   "source": [
    "mask_high = df_education.major.apply(lambda x: ('highschool' in str(x).lower()) or ('high school' in str(x).lower()) )\n",
    "print(count_users(df_education[mask_high]),'unique users with a highschool info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37463 unique users with a bachelor info\n"
     ]
    }
   ],
   "source": [
    "bachelors=['bachelor','bs ','ba ','b.s.','b.a.']\n",
    "mask_ba = df_education.major.apply(lambda x:  any(bachelor in str(x).lower() for bachelor in bachelors))\n",
    "print(count_users(df_education[mask_ba]),'unique users with a bachelor info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33931 unique users with a bachelor info containing exactly 'bachelor'\n"
     ]
    }
   ],
   "source": [
    "bachelors=['bachelor']\n",
    "mask_ba = df_education.major.apply(lambda x:  any(bachelor in str(x).lower() for bachelor in bachelors))\n",
    "print(count_users(df_education[mask_ba]),'unique users with a bachelor info containing exactly \\'bachelor\\'')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will use the later as it is simpler to work with, and 1/3 of the data as training data is enough.\n",
    "##### In the more advanced versions, we use NLP and clustering to encode similer majors, taking into account abbreviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_users=pd.unique(df_education[mask_ba]['user_id']).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Splitting the data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def split_df(users,df):\n",
    "\n",
    "    users_train,users_val=train_test_split( users, test_size = 0.3, random_state = 42)\n",
    "    df_train=df.loc[df['user_id'].isin(users_train)]\n",
    "    df_val=df.loc[df['user_id'].isin(users_val)]\n",
    "    df_test=df.loc[~ df['user_id'].isin(users)]\n",
    "    return df_train,df_val,df_test\n",
    "\n",
    "df_positions_train,df_positions_val,df_positions_test=split_df(training_users,df_positions)\n",
    "df_education_train,df_education_val,df_education_test=split_df(training_users,df_education)\n",
    "df_seniority_train,df_seniority_val,df_seniority_test=split_df(training_users,df_seniority)\n",
    "\n",
    "\n",
    "# checking that we still have every user\n",
    "assert(count_users(df_positions_train)+count_users(df_positions_val)+count_users(df_positions_test)==count_users(df_positions)) #posisions does not have 100k users\n",
    "assert(count_users(df_education_train)+count_users(df_education_val)+count_users(df_education_test)==count_users(df_education))\n",
    "assert(count_users(df_seniority_train)+count_users(df_seniority_val)+count_users(df_seniority_test)==count_users(df_seniority))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import random\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "majors_pipe=None\n",
    "jobs_pipe=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53940"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kmean test, bachelor to be removed\n",
    "# data leakage but intuitively will improve the final accuracy\n",
    "\n",
    "texts=df_education_train['major'].tolist()\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23650"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_text=[]\n",
    "for t in texts:\n",
    "    if (not pd.isnull(t)) and (not 'bachelor' in t.lower() or random.random()<0.33): # removing one third of bechelors to match the rest of the data set\n",
    "        processed_text.append(t)\n",
    "len(processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HHX',\n",
       " 'Master (Cand.mag.)',\n",
       " 'Bachelor (BA)',\n",
       " 'Master of Education (MEd)',\n",
       " 'Associate of Science (A.S.)',\n",
       " 'Master of Arts (MA)',\n",
       " 'Bachelor of Arts (B.A.)',\n",
       " \"Master's degree\",\n",
       " 'Bachelor of Arts (B.A.)',\n",
       " 'Masters, Psychology of Safety and Ergonomics',\n",
       " 'B.S.',\n",
       " 'Bachelor of Arts (BA)',\n",
       " 'Master of Public Administration (MPA)',\n",
       " \"Bachelor's degree\",\n",
       " \"Bachelor's degree\",\n",
       " 'Engineering',\n",
       " 'Bachelors, Psychology',\n",
       " 'TEFL CertificateTEFL Certificate',\n",
       " 'Bachelor of Arts (B.A.)Bachelor of Arts (B.A.)',\n",
       " 'Bachelor of Science (B.S.)']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_text[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 0:\n",
      " of\n",
      " arts\n",
      " bachelor\n",
      " of arts\n",
      " bachelor of\n",
      " bachelor of arts\n",
      " master of\n",
      " master\n",
      " master of arts\n",
      " associate of\n",
      "-------\n",
      "class 1:\n",
      " of\n",
      " master\n",
      " diploma\n",
      " masters\n",
      " doctor\n",
      " degree\n",
      " certificate\n",
      " in\n",
      " doctor of\n",
      " bachelors\n",
      "-------\n",
      "class 2:\n",
      " degree\n",
      " bachelor\n",
      " bachelor degree\n",
      " in\n",
      " degree in\n",
      " bachelor degree in\n",
      " and\n",
      " of\n",
      " science\n",
      " engineering\n",
      "-------\n",
      "class 3:\n",
      " of applied\n",
      " science\n",
      " applied science\n",
      " applied\n",
      " of applied science\n",
      " of\n",
      " bachelor of\n",
      " bachelor of applied\n",
      " bachelor of applied science\n",
      " bachelor\n",
      "-------\n",
      "class 4:\n",
      " of\n",
      " master\n",
      " science\n",
      " master of\n",
      " of science\n",
      " master of science\n",
      " ms\n",
      " of science ms\n",
      " master of science ms\n",
      " science ms\n",
      "-------\n",
      "class 5:\n",
      " of arts\n",
      " bachelor\n",
      " of\n",
      " arts\n",
      " bachelor of arts\n",
      " bachelor of\n",
      " ba\n",
      " bachelor of arts ba\n",
      " of arts ba\n",
      " arts ba\n",
      "-------\n",
      "class 6:\n",
      " science\n",
      " of\n",
      " of science\n",
      " bachelor\n",
      " bachelor of\n",
      " bachelor of science\n",
      " bs\n",
      " bachelor of science bs\n",
      " of science bs\n",
      " science bs\n",
      "-------\n",
      "class 7:\n",
      " of\n",
      " business\n",
      " of business\n",
      " administration\n",
      " of business administration\n",
      " business administration\n",
      " master\n",
      " master of\n",
      " master of business\n",
      " master of business administration\n",
      "-------\n",
      "class 8:\n",
      " master\n",
      " degree\n",
      " master degree\n",
      " in\n",
      " degree in\n",
      " master degree in\n",
      " master 39 degree\n",
      " 39 degree\n",
      " 39\n",
      " master 39\n",
      "-------\n",
      "class 9:\n",
      " engineering\n",
      " of\n",
      " of engineering\n",
      " bachelor\n",
      " bachelor of\n",
      " bachelor of engineering\n",
      " eng\n",
      " of engineering eng\n",
      " engineering eng\n",
      " master\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "number_of_clusters = 10\n",
    "majors_pipe = Pipeline([('vectorizer', CountVectorizer(ngram_range=(1, 4))), ('majors_model', KMeans(n_clusters=number_of_clusters, init='k-means++', max_iter=50, n_init=2))])\n",
    "majors_pipe.fit(processed_text)\n",
    "\n",
    "\n",
    "\n",
    "order_centroids = majors_pipe['majors_model'].cluster_centers_.argsort()[:, ::-1]\n",
    "terms = majors_pipe['vectorizer'].get_feature_names_out()\n",
    "\n",
    "for i in range(0,number_of_clusters):\n",
    "    print(\"class %d:\" % i),\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind])\n",
    "    print('-------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nguye\\AppData\\Local\\Temp/ipykernel_5552/2848042896.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['major_cluster']=major_clusters\n"
     ]
    }
   ],
   "source": [
    "def add_cluster_edu(df):\n",
    "    majors=df['major'].astype(str).tolist()\n",
    "    major_clusters=majors_pipe.predict(majors)\n",
    "    df['major_cluster']=major_clusters\n",
    "add_cluster_edu(df_education_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nguye\\AppData\\Local\\Temp/ipykernel_5552/2848042896.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['major_cluster']=major_clusters\n"
     ]
    }
   ],
   "source": [
    "add_cluster_edu(df_education_val)\n",
    "add_cluster_edu(df_education_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>major</th>\n",
       "      <th>startdate</th>\n",
       "      <th>enddate</th>\n",
       "      <th>major_cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99508</th>\n",
       "      <td>++5SW5MI5/h8X1hMA3QnmQ4ZM3TcQvn1bQ/jHgHWG0kf/b...</td>\n",
       "      <td>BS</td>\n",
       "      <td>1949-01-01</td>\n",
       "      <td>1953-01-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92083</th>\n",
       "      <td>++5qk2+uEmkI/3Z4FrBwDw4ZM3TcQvn1bQ/jHgHWG0kf/b...</td>\n",
       "      <td>BS in Electronics</td>\n",
       "      <td>1973-01-01</td>\n",
       "      <td>1978-01-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92505</th>\n",
       "      <td>++5qk2+uEmkI/3Z4FrBwDw4ZM3TcQvn1bQ/jHgHWG0kf/b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1984-01-01</td>\n",
       "      <td>1987-01-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133238</th>\n",
       "      <td>++6+hv3i5RAVsrWO8q5JEQ5+2cvffV/mNepQVJd0smgtpB...</td>\n",
       "      <td>Master Grande Ecole</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106134</th>\n",
       "      <td>++7kB6m0hI1TgAPmyY1X6A5+2cvffV/mNepQVJd0smgtpB...</td>\n",
       "      <td>Master's Degree</td>\n",
       "      <td>2008-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106774</th>\n",
       "      <td>++7kB6m0hI1TgAPmyY1X6A5+2cvffV/mNepQVJd0smgtpB...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106190</th>\n",
       "      <td>++7kB6m0hI1TgAPmyY1X6A5+2cvffV/mNepQVJd0smgtpB...</td>\n",
       "      <td>BS</td>\n",
       "      <td>1996-01-01</td>\n",
       "      <td>1997-01-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29395</th>\n",
       "      <td>++9DtAOTiRRvECoMIpKbmg4ZM3TcQvn1bQ/jHgHWG0kf/b...</td>\n",
       "      <td>B. Tech</td>\n",
       "      <td>2002-01-01</td>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29488</th>\n",
       "      <td>++9DtAOTiRRvECoMIpKbmg4ZM3TcQvn1bQ/jHgHWG0kf/b...</td>\n",
       "      <td>MSc</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10877</th>\n",
       "      <td>++Bu40VW3TpqnNRejHUsow5+2cvffV/mNepQVJd0smgtpB...</td>\n",
       "      <td>Master of Science (MSc)</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108400</th>\n",
       "      <td>++CkXwiKizxr2GskQ2eBvw5+2cvffV/mNepQVJd0smgtpB...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2002-01-01</td>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108072</th>\n",
       "      <td>++CkXwiKizxr2GskQ2eBvw5+2cvffV/mNepQVJd0smgtpB...</td>\n",
       "      <td>Laurea triennale</td>\n",
       "      <td>2008-01-01</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108331</th>\n",
       "      <td>++CkXwiKizxr2GskQ2eBvw5+2cvffV/mNepQVJd0smgtpB...</td>\n",
       "      <td>Laurea Specialistica</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108306</th>\n",
       "      <td>++CkXwiKizxr2GskQ2eBvw5+2cvffV/mNepQVJd0smgtpB...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145742</th>\n",
       "      <td>++E9PyTRs1v7rNQOa7JJKQ4ZM3TcQvn1bQ/jHgHWG0kf/b...</td>\n",
       "      <td>Master of Science</td>\n",
       "      <td>2003-01-01</td>\n",
       "      <td>2009-12-31</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169075</th>\n",
       "      <td>++EXELjlzUMiVMo6BQUadQ5+2cvffV/mNepQVJd0smgtpB...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-01-01</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169108</th>\n",
       "      <td>++EXELjlzUMiVMo6BQUadQ5+2cvffV/mNepQVJd0smgtpB...</td>\n",
       "      <td>Magister</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159361</th>\n",
       "      <td>++NWXZ8bW3I7VaXV77eiwA5+2cvffV/mNepQVJd0smgtpB...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159096</th>\n",
       "      <td>++NWXZ8bW3I7VaXV77eiwA5+2cvffV/mNepQVJd0smgtpB...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158757</th>\n",
       "      <td>++NWXZ8bW3I7VaXV77eiwA5+2cvffV/mNepQVJd0smgtpB...</td>\n",
       "      <td>Engenheiro Ambiental</td>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146753</th>\n",
       "      <td>++RMgFSqmuf+dN+z7ywy5g5+2cvffV/mNepQVJd0smgtpB...</td>\n",
       "      <td>Erasmus</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>2001-01-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146637</th>\n",
       "      <td>++RMgFSqmuf+dN+z7ywy5g5+2cvffV/mNepQVJd0smgtpB...</td>\n",
       "      <td>licenciatura</td>\n",
       "      <td>1997-01-01</td>\n",
       "      <td>2003-01-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83780</th>\n",
       "      <td>++UCk5ifkH5O/0rIOu/CmQ4ZM3TcQvn1bQ/jHgHWG0kf/b...</td>\n",
       "      <td>BA</td>\n",
       "      <td>1999-01-01</td>\n",
       "      <td>2001-01-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83849</th>\n",
       "      <td>++UCk5ifkH5O/0rIOu/CmQ4ZM3TcQvn1bQ/jHgHWG0kf/b...</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57638</th>\n",
       "      <td>++UVtBJpXMa1E+IOQobfrQ5+2cvffV/mNepQVJd0smgtpB...</td>\n",
       "      <td>BTS ASSISTANT DE MANAGER</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57894</th>\n",
       "      <td>++UVtBJpXMa1E+IOQobfrQ5+2cvffV/mNepQVJd0smgtpB...</td>\n",
       "      <td>BAC SECRETAIRE COMPTABLE</td>\n",
       "      <td>2008-01-01</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37416</th>\n",
       "      <td>++WZyqFWZRHYw7/i9E9vNL4xbHqlXxy8NepQVJd0smgtpB...</td>\n",
       "      <td>Staatlich geprüfter Techniker Elektro-/Informa...</td>\n",
       "      <td>2008-07-01</td>\n",
       "      <td>2012-06-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83195</th>\n",
       "      <td>++XOt+UqpCnbnNoSx+ZCYQ5+2cvffV/mNepQVJd0smgtpB...</td>\n",
       "      <td>edificação</td>\n",
       "      <td>1968-01-01</td>\n",
       "      <td>1970-01-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58695</th>\n",
       "      <td>++XYE+5zBPkZwelWdYHitHAG1BvSkUYANepQVJd0smgtpB...</td>\n",
       "      <td>DIPLOMADO EN CONTABILIDAD GUBERNAMENTAL</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58891</th>\n",
       "      <td>++XYE+5zBPkZwelWdYHitHAG1BvSkUYANepQVJd0smgtpB...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1997-01-01</td>\n",
       "      <td>2001-01-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58694</th>\n",
       "      <td>++XYE+5zBPkZwelWdYHitHAG1BvSkUYANepQVJd0smgtpB...</td>\n",
       "      <td>DIPLOMADO VIRTUAL</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58645</th>\n",
       "      <td>++XYE+5zBPkZwelWdYHitHAG1BvSkUYANepQVJd0smgtpB...</td>\n",
       "      <td>DIPLOMADO VIRTUAL</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58882</th>\n",
       "      <td>++XYE+5zBPkZwelWdYHitHAG1BvSkUYANepQVJd0smgtpB...</td>\n",
       "      <td>DIPLOMADO</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121101</th>\n",
       "      <td>++XeXMfCvvipGArUN9ovGw5+2cvffV/mNepQVJd0smgtpB...</td>\n",
       "      <td>Traducir la Creatividad y la Innovación en Res...</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120840</th>\n",
       "      <td>++XeXMfCvvipGArUN9ovGw5+2cvffV/mNepQVJd0smgtpB...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2001-01-01</td>\n",
       "      <td>2002-01-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120353</th>\n",
       "      <td>++XeXMfCvvipGArUN9ovGw5+2cvffV/mNepQVJd0smgtpB...</td>\n",
       "      <td>Executive MBA</td>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>2008-01-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120760</th>\n",
       "      <td>++XeXMfCvvipGArUN9ovGw5+2cvffV/mNepQVJd0smgtpB...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993-01-01</td>\n",
       "      <td>1999-01-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42433</th>\n",
       "      <td>++YVaejUE9/HxOwEippg7w5+2cvffV/mNepQVJd0smgtpB...</td>\n",
       "      <td>Pondicherry Engineering College</td>\n",
       "      <td>1990-01-01</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137933</th>\n",
       "      <td>++aJ+Yjj9rGQsGtUzuNibzr+/k0/DTn/+K+fv+DIJSUQ20...</td>\n",
       "      <td>DEUG</td>\n",
       "      <td>1997-01-01</td>\n",
       "      <td>1999-01-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138178</th>\n",
       "      <td>++aJ+Yjj9rGQsGtUzuNibzr+/k0/DTn/+K+fv+DIJSUQ20...</td>\n",
       "      <td>B.T.S</td>\n",
       "      <td>1996-01-01</td>\n",
       "      <td>1998-01-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40996</th>\n",
       "      <td>++bfDB2Ys/jvq1t5QkkT6A4ZM3TcQvn1bQ/jHgHWG0kf/b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40552</th>\n",
       "      <td>++bfDB2Ys/jvq1t5QkkT6A4ZM3TcQvn1bQ/jHgHWG0kf/b...</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40622</th>\n",
       "      <td>++bfDB2Ys/jvq1t5QkkT6A4ZM3TcQvn1bQ/jHgHWG0kf/b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175806</th>\n",
       "      <td>++bkrvG+cfpMlkOaPfYxew5+2cvffV/mNepQVJd0smgtpB...</td>\n",
       "      <td>BTS GESTION EN RESTAURATION</td>\n",
       "      <td>1997-01-01</td>\n",
       "      <td>2002-01-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175836</th>\n",
       "      <td>++bkrvG+cfpMlkOaPfYxew5+2cvffV/mNepQVJd0smgtpB...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63765</th>\n",
       "      <td>++danWjua+2ejaEieEVUcQ5+2cvffV/mNepQVJd0smgtpB...</td>\n",
       "      <td>Dipl. Bindvävsmassör</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63775</th>\n",
       "      <td>++danWjua+2ejaEieEVUcQ5+2cvffV/mNepQVJd0smgtpB...</td>\n",
       "      <td>Civilekonom</td>\n",
       "      <td>1985-01-01</td>\n",
       "      <td>1989-01-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63875</th>\n",
       "      <td>++danWjua+2ejaEieEVUcQ5+2cvffV/mNepQVJd0smgtpB...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2001-01-01</td>\n",
       "      <td>2002-01-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63611</th>\n",
       "      <td>++danWjua+2ejaEieEVUcQ5+2cvffV/mNepQVJd0smgtpB...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226103</th>\n",
       "      <td>++qN8gL3PKkIVrT/1c6/yA4ZM3TcQvn1bQ/jHgHWG0kf/b...</td>\n",
       "      <td>Journalism</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>1997-12-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  user_id  \\\n",
       "99508   ++5SW5MI5/h8X1hMA3QnmQ4ZM3TcQvn1bQ/jHgHWG0kf/b...   \n",
       "92083   ++5qk2+uEmkI/3Z4FrBwDw4ZM3TcQvn1bQ/jHgHWG0kf/b...   \n",
       "92505   ++5qk2+uEmkI/3Z4FrBwDw4ZM3TcQvn1bQ/jHgHWG0kf/b...   \n",
       "133238  ++6+hv3i5RAVsrWO8q5JEQ5+2cvffV/mNepQVJd0smgtpB...   \n",
       "106134  ++7kB6m0hI1TgAPmyY1X6A5+2cvffV/mNepQVJd0smgtpB...   \n",
       "106774  ++7kB6m0hI1TgAPmyY1X6A5+2cvffV/mNepQVJd0smgtpB...   \n",
       "106190  ++7kB6m0hI1TgAPmyY1X6A5+2cvffV/mNepQVJd0smgtpB...   \n",
       "29395   ++9DtAOTiRRvECoMIpKbmg4ZM3TcQvn1bQ/jHgHWG0kf/b...   \n",
       "29488   ++9DtAOTiRRvECoMIpKbmg4ZM3TcQvn1bQ/jHgHWG0kf/b...   \n",
       "10877   ++Bu40VW3TpqnNRejHUsow5+2cvffV/mNepQVJd0smgtpB...   \n",
       "108400  ++CkXwiKizxr2GskQ2eBvw5+2cvffV/mNepQVJd0smgtpB...   \n",
       "108072  ++CkXwiKizxr2GskQ2eBvw5+2cvffV/mNepQVJd0smgtpB...   \n",
       "108331  ++CkXwiKizxr2GskQ2eBvw5+2cvffV/mNepQVJd0smgtpB...   \n",
       "108306  ++CkXwiKizxr2GskQ2eBvw5+2cvffV/mNepQVJd0smgtpB...   \n",
       "145742  ++E9PyTRs1v7rNQOa7JJKQ4ZM3TcQvn1bQ/jHgHWG0kf/b...   \n",
       "169075  ++EXELjlzUMiVMo6BQUadQ5+2cvffV/mNepQVJd0smgtpB...   \n",
       "169108  ++EXELjlzUMiVMo6BQUadQ5+2cvffV/mNepQVJd0smgtpB...   \n",
       "159361  ++NWXZ8bW3I7VaXV77eiwA5+2cvffV/mNepQVJd0smgtpB...   \n",
       "159096  ++NWXZ8bW3I7VaXV77eiwA5+2cvffV/mNepQVJd0smgtpB...   \n",
       "158757  ++NWXZ8bW3I7VaXV77eiwA5+2cvffV/mNepQVJd0smgtpB...   \n",
       "146753  ++RMgFSqmuf+dN+z7ywy5g5+2cvffV/mNepQVJd0smgtpB...   \n",
       "146637  ++RMgFSqmuf+dN+z7ywy5g5+2cvffV/mNepQVJd0smgtpB...   \n",
       "83780   ++UCk5ifkH5O/0rIOu/CmQ4ZM3TcQvn1bQ/jHgHWG0kf/b...   \n",
       "83849   ++UCk5ifkH5O/0rIOu/CmQ4ZM3TcQvn1bQ/jHgHWG0kf/b...   \n",
       "57638   ++UVtBJpXMa1E+IOQobfrQ5+2cvffV/mNepQVJd0smgtpB...   \n",
       "57894   ++UVtBJpXMa1E+IOQobfrQ5+2cvffV/mNepQVJd0smgtpB...   \n",
       "37416   ++WZyqFWZRHYw7/i9E9vNL4xbHqlXxy8NepQVJd0smgtpB...   \n",
       "83195   ++XOt+UqpCnbnNoSx+ZCYQ5+2cvffV/mNepQVJd0smgtpB...   \n",
       "58695   ++XYE+5zBPkZwelWdYHitHAG1BvSkUYANepQVJd0smgtpB...   \n",
       "58891   ++XYE+5zBPkZwelWdYHitHAG1BvSkUYANepQVJd0smgtpB...   \n",
       "58694   ++XYE+5zBPkZwelWdYHitHAG1BvSkUYANepQVJd0smgtpB...   \n",
       "58645   ++XYE+5zBPkZwelWdYHitHAG1BvSkUYANepQVJd0smgtpB...   \n",
       "58882   ++XYE+5zBPkZwelWdYHitHAG1BvSkUYANepQVJd0smgtpB...   \n",
       "121101  ++XeXMfCvvipGArUN9ovGw5+2cvffV/mNepQVJd0smgtpB...   \n",
       "120840  ++XeXMfCvvipGArUN9ovGw5+2cvffV/mNepQVJd0smgtpB...   \n",
       "120353  ++XeXMfCvvipGArUN9ovGw5+2cvffV/mNepQVJd0smgtpB...   \n",
       "120760  ++XeXMfCvvipGArUN9ovGw5+2cvffV/mNepQVJd0smgtpB...   \n",
       "42433   ++YVaejUE9/HxOwEippg7w5+2cvffV/mNepQVJd0smgtpB...   \n",
       "137933  ++aJ+Yjj9rGQsGtUzuNibzr+/k0/DTn/+K+fv+DIJSUQ20...   \n",
       "138178  ++aJ+Yjj9rGQsGtUzuNibzr+/k0/DTn/+K+fv+DIJSUQ20...   \n",
       "40996   ++bfDB2Ys/jvq1t5QkkT6A4ZM3TcQvn1bQ/jHgHWG0kf/b...   \n",
       "40552   ++bfDB2Ys/jvq1t5QkkT6A4ZM3TcQvn1bQ/jHgHWG0kf/b...   \n",
       "40622   ++bfDB2Ys/jvq1t5QkkT6A4ZM3TcQvn1bQ/jHgHWG0kf/b...   \n",
       "175806  ++bkrvG+cfpMlkOaPfYxew5+2cvffV/mNepQVJd0smgtpB...   \n",
       "175836  ++bkrvG+cfpMlkOaPfYxew5+2cvffV/mNepQVJd0smgtpB...   \n",
       "63765   ++danWjua+2ejaEieEVUcQ5+2cvffV/mNepQVJd0smgtpB...   \n",
       "63775   ++danWjua+2ejaEieEVUcQ5+2cvffV/mNepQVJd0smgtpB...   \n",
       "63875   ++danWjua+2ejaEieEVUcQ5+2cvffV/mNepQVJd0smgtpB...   \n",
       "63611   ++danWjua+2ejaEieEVUcQ5+2cvffV/mNepQVJd0smgtpB...   \n",
       "226103  ++qN8gL3PKkIVrT/1c6/yA4ZM3TcQvn1bQ/jHgHWG0kf/b...   \n",
       "\n",
       "                                                    major   startdate  \\\n",
       "99508                                                  BS  1949-01-01   \n",
       "92083                                   BS in Electronics  1973-01-01   \n",
       "92505                                                 NaN  1984-01-01   \n",
       "133238                                Master Grande Ecole  2013-01-01   \n",
       "106134                                    Master's Degree  2008-01-01   \n",
       "106774                                                NaN  2012-01-01   \n",
       "106190                                                 BS  1996-01-01   \n",
       "29395                                             B. Tech  2002-01-01   \n",
       "29488                                                 MSc  2009-01-01   \n",
       "10877                             Master of Science (MSc)  2010-01-01   \n",
       "108400                                                NaN  2002-01-01   \n",
       "108072                                   Laurea triennale  2008-01-01   \n",
       "108331                               Laurea Specialistica  2012-01-01   \n",
       "108306                                                NaN  2016-01-01   \n",
       "145742                                  Master of Science  2003-01-01   \n",
       "169075                                                NaN  2008-01-01   \n",
       "169108                                           Magister  2011-01-01   \n",
       "159361                                                NaN  2004-01-01   \n",
       "159096                                                NaN  2010-01-01   \n",
       "158757                               Engenheiro Ambiental  2006-01-01   \n",
       "146753                                            Erasmus  2000-01-01   \n",
       "146637                                       licenciatura  1997-01-01   \n",
       "83780                                                  BA  1999-01-01   \n",
       "83849                                     Master's degree  2010-01-01   \n",
       "57638                            BTS ASSISTANT DE MANAGER  2009-01-01   \n",
       "57894                            BAC SECRETAIRE COMPTABLE  2008-01-01   \n",
       "37416   Staatlich geprüfter Techniker Elektro-/Informa...  2008-07-01   \n",
       "83195                                          edificação  1968-01-01   \n",
       "58695             DIPLOMADO EN CONTABILIDAD GUBERNAMENTAL  2015-01-01   \n",
       "58891                                                 NaN  1997-01-01   \n",
       "58694                                   DIPLOMADO VIRTUAL  2016-01-01   \n",
       "58645                                   DIPLOMADO VIRTUAL  2016-01-01   \n",
       "58882                                           DIPLOMADO  2016-01-01   \n",
       "121101  Traducir la Creatividad y la Innovación en Res...  2014-01-01   \n",
       "120840                                                NaN  2001-01-01   \n",
       "120353                                      Executive MBA  2007-01-01   \n",
       "120760                                                NaN  1993-01-01   \n",
       "42433                     Pondicherry Engineering College  1990-01-01   \n",
       "137933                                               DEUG  1997-01-01   \n",
       "138178                                              B.T.S  1996-01-01   \n",
       "40996                                                 NaN  2009-01-01   \n",
       "40552                                           Marketing  2007-01-01   \n",
       "40622                                                 NaN  2009-01-01   \n",
       "175806                        BTS GESTION EN RESTAURATION  1997-01-01   \n",
       "175836                                                NaN         NaN   \n",
       "63765                                Dipl. Bindvävsmassör  1992-01-01   \n",
       "63775                                         Civilekonom  1985-01-01   \n",
       "63875                                                 NaN  2001-01-01   \n",
       "63611                                                 NaN  2010-01-01   \n",
       "226103                                         Journalism  1992-01-01   \n",
       "\n",
       "           enddate  major_cluster  \n",
       "99508   1953-01-01              1  \n",
       "92083   1978-01-01              1  \n",
       "92505   1987-01-01              1  \n",
       "133238  2016-01-01              1  \n",
       "106134         NaN              8  \n",
       "106774  2013-01-01              1  \n",
       "106190  1997-01-01              1  \n",
       "29395   2006-01-01              1  \n",
       "29488   2010-01-01              1  \n",
       "10877   2016-01-01              4  \n",
       "108400  2007-01-01              1  \n",
       "108072  2012-01-01              1  \n",
       "108331  2015-01-01              1  \n",
       "108306         NaN              1  \n",
       "145742  2009-12-31              4  \n",
       "169075  2011-01-01              1  \n",
       "169108  2013-01-01              1  \n",
       "159361  2005-01-01              1  \n",
       "159096  2012-01-01              1  \n",
       "158757  2009-01-01              1  \n",
       "146753  2001-01-01              1  \n",
       "146637  2003-01-01              1  \n",
       "83780   2001-01-01              1  \n",
       "83849   2012-01-01              8  \n",
       "57638   2011-01-01              1  \n",
       "57894   2009-01-01              1  \n",
       "37416   2012-06-01              1  \n",
       "83195   1970-01-01              1  \n",
       "58695   2016-01-01              1  \n",
       "58891   2001-01-01              1  \n",
       "58694   2016-01-01              1  \n",
       "58645   2016-01-01              1  \n",
       "58882   2016-01-01              1  \n",
       "121101  2014-01-01              1  \n",
       "120840  2002-01-01              1  \n",
       "120353  2008-01-01              1  \n",
       "120760  1999-01-01              1  \n",
       "42433   2004-01-01              1  \n",
       "137933  1999-01-01              1  \n",
       "138178  1998-01-01              1  \n",
       "40996   2011-01-01              1  \n",
       "40552   2009-01-01              1  \n",
       "40622   2009-01-01              1  \n",
       "175806  2002-01-01              1  \n",
       "175836         NaN              1  \n",
       "63765   1995-01-01              1  \n",
       "63775   1989-01-01              1  \n",
       "63875   2002-01-01              1  \n",
       "63611   2012-01-01              1  \n",
       "226103  1997-12-31              1  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_education_test.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>major</th>\n",
       "      <th>startdate</th>\n",
       "      <th>enddate</th>\n",
       "      <th>major_cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97609</th>\n",
       "      <td>+02gInNMb8KUKcP5UL7dCQ5+2cvffV/mNepQVJd0smgtpB...</td>\n",
       "      <td>Bachelor of Applied Science (BASc)</td>\n",
       "      <td>1999-01-01</td>\n",
       "      <td>2003-01-01</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62419</th>\n",
       "      <td>+0Tt6rmm+fU7MmvucIQRyQ4ZM3TcQvn1bQ/jHgHWG0kf/b...</td>\n",
       "      <td>Bachelor of Applied Science (BASc)</td>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225417</th>\n",
       "      <td>+HpcatofY00V0nHIJ/rb+g4ZM3TcQvn1bQ/jHgHWG0kf/b...</td>\n",
       "      <td>Bachelor of Applied Science</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>2011-12-31</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24505</th>\n",
       "      <td>+TloblZJw/z5fOIdmSWI2w5+2cvffV/mNepQVJd0smgtpB...</td>\n",
       "      <td>Bachelor of Applied Science (BASc)</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51981</th>\n",
       "      <td>+brlwswF32W6B4DHJJ5IJA5+2cvffV/mNepQVJd0smgtpB...</td>\n",
       "      <td>Bachelor of Applied Science (BASc)</td>\n",
       "      <td>1973-01-01</td>\n",
       "      <td>1977-01-01</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  user_id  \\\n",
       "97609   +02gInNMb8KUKcP5UL7dCQ5+2cvffV/mNepQVJd0smgtpB...   \n",
       "62419   +0Tt6rmm+fU7MmvucIQRyQ4ZM3TcQvn1bQ/jHgHWG0kf/b...   \n",
       "225417  +HpcatofY00V0nHIJ/rb+g4ZM3TcQvn1bQ/jHgHWG0kf/b...   \n",
       "24505   +TloblZJw/z5fOIdmSWI2w5+2cvffV/mNepQVJd0smgtpB...   \n",
       "51981   +brlwswF32W6B4DHJJ5IJA5+2cvffV/mNepQVJd0smgtpB...   \n",
       "\n",
       "                                     major   startdate     enddate  \\\n",
       "97609   Bachelor of Applied Science (BASc)  1999-01-01  2003-01-01   \n",
       "62419   Bachelor of Applied Science (BASc)  2007-01-01  2010-01-01   \n",
       "225417         Bachelor of Applied Science  2010-01-01  2011-12-31   \n",
       "24505   Bachelor of Applied Science (BASc)  2011-01-01  2013-01-01   \n",
       "51981   Bachelor of Applied Science (BASc)  1973-01-01  1977-01-01   \n",
       "\n",
       "        major_cluster  \n",
       "97609               3  \n",
       "62419               3  \n",
       "225417              3  \n",
       "24505               3  \n",
       "51981               3  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_education_train[df_education_train['major_cluster']==3].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changing dates and text format \n",
      "\n",
      "completing position end dates...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nguye\\anaconda3\\envs\\envTF\\lib\\site-packages\\pandas\\core\\indexing.py:1773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n",
      "C:\\Users\\nguye\\anaconda3\\envs\\envTF\\lib\\site-packages\\pandas\\core\\indexing.py:1951: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[selected_item_labels] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added 24017 values \n",
      "\n",
      "completing education end dates...\n",
      "added 1815 values \n",
      "\n",
      "completing education start dates...\n",
      "average length:  3.608725981355846 yrs\n",
      "added 398 values \n",
      "\n",
      "completing position end dates...\n",
      "average length:  3.962133030775858 yrs\n",
      "added 21 values \n",
      "\n",
      "completing education remaining dates...\n",
      "average start date:  2003.2742277481523 yrs\n",
      "average end date:  2006.882953729532 yrs\n",
      "added 6235 values \n",
      "\n",
      "completing position remaining dates...\n",
      "average start date:  2010.1799402438633 yrs\n",
      "average end date:  2014.1420732741742 yrs\n",
      "added 1635 values \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nguye\\anaconda3\\envs\\envTF\\lib\\site-packages\\pandas\\core\\generic.py:6392: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return self._update_inplace(result)\n",
      "C:\\Users\\nguye\\anaconda3\\envs\\envTF\\lib\\site-packages\\pandas\\util\\_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "class DataTransformer:\n",
    "    # to preven data leakage\n",
    "    #class constants, used for test data too, but they are only changed with the training data when fit=true\n",
    "    \n",
    "    avg_length_job= avg_length_edu = avg_end_job = avg_start_job= avg_end_edu = avg_start_edu =0\n",
    "    \n",
    "    TEST=None\n",
    "    def __init__(self,df_positions,df_education,df_seniority):\n",
    "        self.df_positions = df_positions\n",
    "        self.df_education=df_education\n",
    "        self.df_seniority = df_seniority\n",
    "    ### \n",
    "    def format_to_size(self,df,labels=False):\n",
    "        def to_fixed_size(df,cols,size):\n",
    "            for col in cols:\n",
    "                df[col] = df[col].apply(lambda x: x[0:size] if (len(x)>size) else  (x + (size-len(x)) * [x[-1]]))\n",
    "            \n",
    "            return df\n",
    "        \n",
    "        return to_fixed_size(df,['enddate_y','startdate_y','seniority','enddate_x','startdate_x','major_cluster'],10)\n",
    "    ###\n",
    "    def get_labels(self,df,remove_info=False):\n",
    "        df['label']=None\n",
    "        def get_first_index(mylist, substring):\n",
    "            for i, s in enumerate(mylist):\n",
    "                if substring in s:\n",
    "                      return i\n",
    "            return -1\n",
    "        for index, row in df.iterrows():\n",
    "            i=get_first_index(row['major'],'bachelor')\n",
    "            birth=row['startdate_y'][i]-18\n",
    "            if i!=-1:\n",
    "                df.loc[index,'label'] = birth \n",
    "                if remove_info and len(row['enddate_y'])>1 and random.random()>0.3: # remove bachelor info for training\n",
    "                    df.at[index,'enddate_y'] = row['enddate_y'][:i]+row['enddate_y'][i+1:]\n",
    "                    df.at[index,'startdate_y'] = row['startdate_y'][:i]+row['startdate_y'][i+1:]\n",
    "                    df.at[index,'major'] =  row['major'][:i]+row['major'][i+1:]\n",
    "            else:\n",
    "                print('ERROR COULD NOT GET LABEL FOR USER:', row.index.name)\n",
    "        return df\n",
    "    ###\n",
    "    def merge_pd(self,df_positions, df_education,df_seniority,labels=False,remove_info=False):\n",
    "        # sorting by startdate for later:\n",
    "        df_positions.sort_values(by=['startdate'],inplace=True)\n",
    "        df_education.sort_values(by=['startdate'],inplace=True)\n",
    "        \n",
    "        df=df_positions.merge(df_seniority, how='right',left_on=['user_id','jobtitle'], right_on=['user_id','jobtitle'])\n",
    "        df=df.groupby('user_id').agg(lambda x: list(x))\n",
    "        df_education_temp=df_education.groupby('user_id').agg(lambda x: list(x))\n",
    "        df=df.merge(df_education_temp, how='outer', left_on='user_id', right_on='user_id')\n",
    "        \n",
    "        df['startdate_x']=df.apply(lambda row: [max(row['enddate_y']) if pd.isnull(date) else date for date in row['startdate_x'] ] ,axis=1)\n",
    "        now = datetime.now()\n",
    "        today=now.year+now.month/13\n",
    "        df['enddate_x']=df['enddate_x'].apply(lambda dates: [today if pd.isnull(date) else date for date in dates])\n",
    "        \n",
    "        if labels: # add labels\n",
    "            df=self.get_labels(df,remove_info)\n",
    "        return df\n",
    "    ###\n",
    "    def transform_pd(self,df_positions, df_education,df_seniority,fit=False):\n",
    "        \n",
    "        def to_lower_case(df,col):\n",
    "            df.loc[:,col] =  df[col].str.lower()\n",
    "            return df \n",
    "        def to_datetime(df,col):\n",
    "            df.loc[:,col] =  pd.to_datetime(df[col], format='%Y-%m-%d')\n",
    "            df.loc[:,col] =  df[col].dt.year+ df[col].dt.month/13\n",
    "            return df\n",
    "        print('changing dates and text format \\n')\n",
    "\n",
    "        df_education = df_education.pipe(to_lower_case, col='major').pipe(to_datetime,col='startdate').pipe(to_datetime,col='enddate')\n",
    "        df_positions = df_positions.pipe(to_lower_case, col='jobtitle').pipe(to_datetime,col='startdate').pipe(to_datetime,col='enddate')\n",
    "        df_seniority = df_seniority.pipe(to_lower_case, col='jobtitle')\n",
    "        \n",
    "        def fill_end_dates(df):\n",
    "            now = datetime.now()\n",
    "            today=now.year+now.month/13\n",
    "            #print('today',today)\n",
    "            before=df['enddate'].isna().sum()\n",
    "            df.loc[:,'enddate']=df.loc[:,:].apply(lambda row: today if pd.isnull(row['enddate']) and (not pd.isnull(row['startdate'])) else row['enddate'],axis=1)\n",
    "            print('added',before-df['enddate'].isna().sum(),'values \\n')\n",
    "            return df\n",
    "\n",
    "        print('completing position end dates...')\n",
    "\n",
    "        df_positions=fill_end_dates(df_positions)\n",
    "        print('completing education end dates...')\n",
    "        df_education=fill_end_dates(df_education)\n",
    "\n",
    "        def fill_startdate(df,typ):\n",
    "            df_nona=df[['startdate','enddate']].dropna(how='all',inplace=False)\n",
    "            df_nona['length']=df_nona['enddate']-df_nona['startdate']\n",
    "            avg_length=0\n",
    "            if fit:\n",
    "                if typ=='edu':\n",
    "                    DataTransformer.avg_length_edu=avg_length=df_nona[\"length\"].mean()\n",
    "                else:\n",
    "                    DataTransformer.avg_length_job=avg_length=df_nona[\"length\"].mean()\n",
    "            else:\n",
    "                if typ=='edu':\n",
    "                    avg_length=DataTransformer.avg_length_edu\n",
    "                else:\n",
    "                    avg_length= DataTransformer.avg_length_job\n",
    "                \n",
    "            print('average length: ',avg_length,'yrs')\n",
    "            before=df['startdate'].isna().sum()\n",
    "            df['startdate'].fillna(df['enddate']-avg_length, inplace=True)\n",
    "            print('added',before-df['startdate'].isna().sum(),'values \\n')\n",
    "            return df\n",
    "        print('completing education start dates...')\n",
    "        df_education=fill_startdate(df_education,'edu')\n",
    "        print('completing position end dates...')\n",
    "        df_positions=fill_startdate(df_positions,'job')\n",
    "        \n",
    "        def fill_dates_missingall(df,typ):\n",
    "            df_nona=df[['startdate','enddate']].dropna(how='all',inplace=False)\n",
    "            #df_nona['length']=df_nona['enddate']-df_nona['startdate']\n",
    "            \n",
    "            avg_start=avg_end=0\n",
    "            if fit:\n",
    "                if typ=='edu':\n",
    "                    DataTransformer.avg_start_edu=avg_start=df_nona[\"startdate\"].mean()\n",
    "                    DataTransformer.avg_end_edu=avg_end=df_nona[\"enddate\"].mean()\n",
    "                else:\n",
    "                    DataTransformer.avg_start_job=avg_start=df_nona[\"startdate\"].mean()\n",
    "                    DataTransformer.avg_end_job=avg_end=df_nona[\"enddate\"].mean()\n",
    "            else:\n",
    "                if typ=='edu':\n",
    "                    avg_start=DataTransformer.avg_start_edu\n",
    "                    avg_end=DataTransformer.avg_end_edu\n",
    "                else:\n",
    "                    avg_start=DataTransformer.avg_start_job\n",
    "                    avg_end=DataTransformer.avg_end_job\n",
    "            \n",
    "                \n",
    "            print('average start date: ',avg_start,'yrs')\n",
    "            print('average end date: ',avg_end,'yrs')\n",
    "            before=df['startdate'].isna().sum()\n",
    "            df['startdate'].fillna(avg_start, inplace=True)\n",
    "            df['enddate'].fillna(avg_end, inplace=True)\n",
    "            print('added',before-df['startdate'].isna().sum(),'values \\n')\n",
    "            return df  \n",
    "        print('completing education remaining dates...')\n",
    "        df_education=fill_dates_missingall(df_education,'edu')\n",
    "        print('completing position remaining dates...')\n",
    "        df_positions=fill_dates_missingall(df_positions,'job')\n",
    "        \n",
    "        # filling missing education and positions\n",
    "        df_positions['jobtitle'].fillna('positions', inplace=True)\n",
    "        df_seniority['jobtitle'].fillna('positions', inplace=True)\n",
    "        df_education['major'].fillna('education', inplace=True)\n",
    "        \n",
    "        #filling missing seniority information\n",
    "        df_seniority['seniority'].fillna((df_seniority['seniority'].mean()), inplace=True)\n",
    "            \n",
    "        \n",
    "        return df_positions,df_education,df_seniority\n",
    "    \n",
    "    ####\n",
    "    def transform(self,fit=False,labels=False,remove_info=False):\n",
    "        self.df_positions,self.df_education,self.df_seniority=self.transform_pd(self.df_positions, self.df_education,self.df_seniority,fit)\n",
    "        merged=self.merge_pd(self.df_positions,self.df_education,self.df_seniority,labels,remove_info)\n",
    "        \n",
    "        \n",
    "        return self.format_to_size(merged,labels)\n",
    "    \n",
    "    \n",
    "dataTransformer = DataTransformer(df_positions_train,df_education_train,df_seniority_train)\n",
    "train_data =dataTransformer.transform(fit=True,labels=True,remove_info=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols=['enddate_y','startdate_y','seniority','enddate_x','startdate_x','major_cluster']\n",
    "\n",
    "\n",
    "X=np.asarray(train_data[feature_cols].values.tolist())\n",
    "# matrix dim for emsemble method\n",
    "X=np.reshape(X, (len(X), X.shape[1]*X.shape[2]))\n",
    "\n",
    "# gets rid of future warning\n",
    "y=np.asarray(train_data[['label']]).reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "#### After testing multiple models from sklearn, ensemble methods were the ones that worked the best\n",
    "\n",
    "#### We are going to investigate Neural networks later "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split( X, y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "# defining parameter range \n",
    "# Number of trees in random forest\n",
    "n_estimators = [200]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x*10) for x in range(1,5)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "njobs=[-1]\n",
    "# Create the random grid\n",
    "param_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap,\n",
    "              'n_jobs' : njobs\n",
    "                }\n",
    "   \n",
    "#grid = RandomizedSearchCV(RandomForestRegressor(), param_grid, refit = True, verbose = 10) \n",
    "   \n",
    "# fitting the model for grid search \n",
    "#grid.fit(X_train, y_train) \n",
    " \n",
    "# print best parameter after tuning \n",
    "#print(grid.best_params_) \n",
    "#grid_predictions = grid.predict(X_val) \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 0.8450564065131023\n",
      "validation mean abs error 2.279859284732923\n",
      "validation RMSE 4.083517739540363\n"
     ]
    }
   ],
   "source": [
    "# Scaler not necessary here but it make it easier to change model, when we have to use it\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('RandomForestRegressor', RandomForestRegressor(n_estimators=200,n_jobs=-1,min_samples_split=2,max_features='auto',min_samples_leaf=2,bootstrap=True,max_depth=40))])\n",
    "pipe.fit(X_train,y_train)\n",
    "y_pred = pipe.predict(X_val)\n",
    "print('score', pipe.score(X_val,y_val))\n",
    "print('validation mean abs error',mean_absolute_error(y_val, y_pred))\n",
    "print('validation RMSE',mean_squared_error(y_val, y_pred,squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTransformer = DataTransformer(df_positions_test,df_education_test,df_seniority_test)\n",
    "test_data =dataTransformer.transform(fit=False,labels=False,remove_info=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=np.asarray(test_data[feature_cols].values.tolist())\n",
    "# matrix dim for emsemble method\n",
    "X_test=np.reshape(X_test, (len(X_test), X_test.shape[1]*X_test.shape[2]))\n",
    "y_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['label'] = y_pred\n",
    "test_data['true_or_predicted']=False\n",
    "\n",
    "train_data['true_or_predicted']=True\n",
    "\n",
    "df_all=pd.concat([train_data, test_data], axis=0)\n",
    "\n",
    "now = datetime.now()\n",
    "today=now.year+now.month/13\n",
    "\n",
    "df_all['age']=(today-df_all['label']).astype(int)\n",
    "df_all=df_all[['age','true_or_predicted']]\n",
    "df_all.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamere=df_all[~df_all['true_or_predicted']]\n",
    "tamere.reset_index(drop=True)\n",
    "tamere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (33931,33931+5):\n",
    "    user=tamere.loc[i,'user_id']\n",
    "    get_user_history(user)\n",
    "    print('=========')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN and perception with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import shuffle\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot configurations\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping the same split for consistency\n",
    "\n",
    "scaler=StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "\n",
    "X_train=np.reshape(X_train, (len(X_train),original_shape[1],original_shape[2]))\n",
    "X_train=np.swapaxes(X_train,1,2)\n",
    "X_val=scaler.transform(X_val) # no fit\n",
    "X_val=np.reshape(X_val, (len(X_val),original_shape[1],original_shape[2]))\n",
    "X_val=np.swapaxes(X_val,1,2)\n",
    "X_val.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_scaler=StandardScaler()\n",
    "y_train=label_scaler.fit_transform(y_train.reshape(-1, 1)).reshape(-1)\n",
    "y_val=label_scaler.transform(y_val.reshape(-1, 1)).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "model = tf.keras.Sequential() \n",
    "model.add(layers.Input((original_shape[2],original_shape[1])))\n",
    "model.add(layers.LSTM(1024, return_sequences=True))\n",
    "model.add(layers.LSTM(256, input_shape=X.shape, return_sequences=False))\n",
    "model.add(layers.Dense(32,activation='relu'))\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "print(model.summary() )\n",
    "model.compile(loss='mean_squared_error',\n",
    "    optimizer=tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.0003),\n",
    "              metrics=['accuracy']) \n",
    "history_LSTM = model.fit(X_train, y_train, validation_data=(X_val, y_val),batch_size=128, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = model.predict(X_val)\n",
    "y_pred2 =label_scaler.inverse_transform(y_pred2.reshape(-1,1)).reshape(-1)\n",
    "y_true =label_scaler.inverse_transform(y_val.reshape(-1,1)).reshape(-1)\n",
    "accs=[abs(y_pred2[i]-y_true[i]) for i in range(len(y_true))]\n",
    "sum(accs)/len(accs)\n",
    "print('RMSE',mean_squared_error(y_true, y_pred,squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.reshape(X_train, (len(X_train),original_shape[1]*original_shape[2]))\n",
    "X_val=np.reshape(X_val, (len(X_val),original_shape[1]*original_shape[2]))\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "model_perceptron = tf.keras.Sequential() \n",
    "model_perceptron.add(layers.Input((original_shape[1]*original_shape[2])))\n",
    "model_perceptron.add(layers.Dense(30,activation='relu',kernel_regularizer=tf.keras.regularizers.L1(0.001)))\n",
    "model_perceptron.add(layers.Dense(20,activation='relu',kernel_regularizer=tf.keras.regularizers.L1(0.001)))\n",
    "model_perceptron.add(layers.Dense(10,activation='relu'))\n",
    "model_perceptron.add(layers.Dense(5,activation='relu'))\n",
    "model_perceptron.add(layers.Dense(5,activation='relu'))\n",
    "model_perceptron.add(layers.Dense(10,activation='relu',kernel_regularizer=tf.keras.regularizers.L1(0.001)))\n",
    "model_perceptron.add(layers.Dense(1))\n",
    "\n",
    "print(model_perceptron.summary() )\n",
    "model_perceptron.compile(loss='mean_squared_error',\n",
    "    optimizer=tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001),\n",
    "              metrics=['accuracy']) \n",
    "history_perceptron = model_perceptron.fit(X_train, y_train, validation_data=(X_val, y_val),batch_size=128, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val =label_scaler.inverse_transform(y_val.reshape(-1,1)).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3 = model_perceptron.predict(X_val)\n",
    "print(y_pred3.shape)\n",
    "y_pred3 =label_scaler.inverse_transform(y_pred3.reshape(-1,1)).reshape(-1)\n",
    "\n",
    "accs=[abs(y_pred3[i]-y_val[i]) for i in range(len(y_val))]\n",
    "print('avg abs err:',sum(accs)/len(accs))\n",
    "print('RMSE',mean_squared_error(y_val, y_pred3,squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction on all the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explaination end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe2dff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Usefull functions\n",
    "\n",
    "\n",
    "def to_lower_case(df,col):\n",
    "    df[col] =  df[col].str.lower()\n",
    "    return df \n",
    "def to_datetime(df,col):\n",
    "    df[col] =  pd.to_datetime(df[col], format='%Y-%m-%d')\n",
    "    df[col] =  df[col].dt.year+ df[col].dt.month/13\n",
    "    return df\n",
    "\n",
    "print('changing dates and text format \\n')\n",
    "\n",
    "df_education = df_education.pipe(to_lower_case, col='major').pipe(to_datetime,col='startdate').pipe(to_datetime,col='enddate')\n",
    "df_positions = df_positions.pipe(to_lower_case, col='jobtitle').pipe(to_datetime,col='startdate').pipe(to_datetime,col='enddate')\n",
    "df_seniority = df_seniority.pipe(to_lower_case, col='jobtitle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling missing values\n",
    "\n",
    "def fill_end_dates(df):\n",
    "    now = datetime.now()\n",
    "    today=now.year+now.month/13\n",
    "    #print('today',today)\n",
    "    before=df['enddate'].isna().sum()\n",
    "    df['enddate']=df.apply(lambda row: today if pd.isnull(row['enddate']) and (not pd.isnull(row['startdate'])) else row['enddate'],axis=1)\n",
    "    print('added',before-df['enddate'].isna().sum(),'values \\n')\n",
    "    return df\n",
    "\n",
    "print('completing position end dates...')\n",
    "\n",
    "df_positions=fill_end_dates(df_positions)\n",
    "print('completing education end dates...')\n",
    "df_education=fill_end_dates(df_education)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_startdate(df):\n",
    "    df_nona=df[['startdate','enddate']].dropna(how='all',inplace=False)\n",
    "    df_nona['length']=df_nona['enddate']-df_nona['startdate']\n",
    "    avg_length=df_nona[\"length\"].mean()\n",
    "    print('average length: ',avg_length,'yrs')\n",
    "    before=df['startdate'].isna().sum()\n",
    "    df['startdate'].fillna(df['enddate']-avg_length, inplace=True)\n",
    "    print('added',before-df['startdate'].isna().sum(),'values \\n')\n",
    "    return df\n",
    "print('completing education start dates...')\n",
    "df_education=fill_startdate(df_education)\n",
    "print('completing position end dates...')\n",
    "df_positions=fill_startdate(df_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_dates_missingall(df):\n",
    "    df_nona=df[['startdate','enddate']].dropna(how='all',inplace=False)\n",
    "    #df_nona['length']=df_nona['enddate']-df_nona['startdate']\n",
    "    avg_start=df_nona[\"startdate\"].mean()\n",
    "    avg_end=df_nona[\"enddate\"].mean()\n",
    "    print('average start date: ',avg_start,'yrs')\n",
    "    print('average end date: ',avg_end,'yrs')\n",
    "    before=df['startdate'].isna().sum()\n",
    "    df['startdate'].fillna(avg_start, inplace=True)\n",
    "    df['enddate'].fillna(avg_end, inplace=True)\n",
    "    print('added',before-df['startdate'].isna().sum(),'values \\n')\n",
    "    return df  \n",
    "print('completing education remaining dates...')\n",
    "df_education=fill_dates_missingall(df_education)\n",
    "print('completing position remaining dates...')\n",
    "df_positions=fill_dates_missingall(df_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling missing education and positions\n",
    "df_positions['jobtitle'].fillna('positions', inplace=True)\n",
    "df_seniority['jobtitle'].fillna('positions', inplace=True)\n",
    "df_education['major'].fillna('education', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seniority['seniority'].fillna((df_seniority['seniority'].mean()), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting by startdate for later:\n",
    "df_positions.sort_values(by=['startdate'],inplace=True)\n",
    "df_education.sort_values(by=['startdate'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_education.isna().sum())\n",
    "print(df_seniority.isna().sum())\n",
    "df_positions.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_positions.merge(df_seniority, how='right',left_on=['user_id','jobtitle'], right_on=['user_id','jobtitle']) # only position lacks users, hence right join\n",
    "df=df.groupby('user_id').agg(lambda x: list(x))\n",
    "df_education_temp=df_education.groupby('user_id').agg(lambda x: list(x))\n",
    "df=df.merge(df_education_temp, how='outer', left_on='user_id', right_on='user_id')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id ='++NWXZ8bW3I7VaXV77eiwA5+2cvffV/mNepQVJd0smgtpBr4MGMFJQ=='\n",
    "print(test_id)\n",
    "get_user_history(test_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_count={'jobtitle': 0,'startdate_x':0,'enddate_x':0,'startdate_y':0,'startdate_y':0,'major':0,'seniority':0}\n",
    "mask=[]\n",
    "\n",
    "for rowIndex, row in df.iterrows(): \n",
    "    ismissing=False\n",
    "    for i, value in row.items():\n",
    "        for n in value:\n",
    "            if (pd.isnull(n)):\n",
    "                ismissing=True\n",
    "                missing_count[i]=missing_count[i]+1\n",
    "    if ismissing:\n",
    "        mask.append(True)\n",
    "    else:\n",
    "        mask.append(False)\n",
    "missing_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([x for x in mask if x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['startdate_x']=df.apply(lambda row: [max(row['enddate_y']) if pd.isnull(date) else date for date in row['startdate_x'] ] ,axis=1)\n",
    "now = datetime.now()\n",
    "today=now.year+now.month/13\n",
    "df['enddate_x']=df['enddate_x'].apply(lambda dates: [today if pd.isnull(date) else date for date in dates])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
